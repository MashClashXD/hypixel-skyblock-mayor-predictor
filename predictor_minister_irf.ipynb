{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f157c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOP 15 MOST USEFUL FEATURES FOR THE MODEL\n",
      "================================================================================\n",
      "Rank Feature                                  Importance   Type           \n",
      "--------------------------------------------------------------------------------\n",
      "1    interaction_perk_Perks.SlashedPricing * interaction_perk_Perks.SlayerXPBuff * perk_Perks.SlashedPricing 0.010973     Interaction    \n",
      "2    interaction_interaction_perk_Perks.Prospection * perk_Perks.MiningFiesta * perk_Perks.MiningFiesta 0.010387     Interaction    \n",
      "3    interaction_perk_Perks.Prospection * perk_Perks.MiningFiesta 0.010387     Interaction    \n",
      "4    perk_Perks.MiningFiesta                  0.010222     Perk           \n",
      "5    interaction_interaction_cand_Aatrox * perk_Perks.SlayerXPBuff * interaction_cand_Aatrox * perk_Perks.SlashedPricing 0.009950     Interaction    \n",
      "6    interaction_perk_Perks.EZPZ * interaction_perk_Perks.Benediction * perk_Perks.EZPZ 0.009731     Interaction    \n",
      "7    interaction_perk_Perks.FishingXPBuff * perk_Perks.FishingFestival 0.009582     Interaction    \n",
      "8    interaction_interaction_cand_Aatrox * perk_Perks.SlayerXPBuff * interaction_perk_Perks.SlayerXPBuff * perk_Perks.SlashedPricing 0.009537     Interaction    \n",
      "9    interaction_interaction_cand_Paul * perk_Perks.EZPZ * interaction_perk_Perks.Benediction * perk_Perks.EZPZ 0.009493     Interaction    \n",
      "10   interaction_interaction_perk_Perks.PetXPBuff * perk_Perks.MythologicalRitual * interaction_cand_Diana * perk_Perks.MythologicalRitual 0.009475     Interaction    \n",
      "11   interaction_perk_Perks.PetXPBuff * perk_Perks.MythologicalRitual 0.009451     Interaction    \n",
      "12   interaction_perk_Perks.FishingFestival * interaction_perk_Perks.FishingXPBuff * perk_Perks.FishingFestival 0.009386     Interaction    \n",
      "13   interaction_interaction_cand_Aatrox * perk_Perks.SlashedPricing * interaction_perk_Perks.SlayerXPBuff * perk_Perks.SlashedPricing 0.009375     Interaction    \n",
      "14   interaction_perk_Perks.MiningXPBuff * perk_Perks.MiningFiesta 0.009043     Interaction    \n",
      "15   interaction_perk_Perks.SlayerXPBuff * perk_Perks.SlashedPricing 0.008951     Interaction    \n",
      "\n",
      "================================================================================\n",
      "FEATURE TYPE BREAKDOWN IN TOP 15\n",
      "================================================================================\n",
      "Interaction    : 14 features ( 93.3%)\n",
      "Perk           :  1 features (  6.7%)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "COMPARISON: iRF vs BASELINE RANDOM FOREST\n",
      "============================================================\n",
      "\n",
      "Baseline Random Forest (4-Fold CV):\n",
      "Accuracy: 0.5020 ± 0.0338\n",
      "Precision Weighted: 0.4780 ± 0.0616\n",
      "Recall Weighted: 0.5020 ± 0.0338\n",
      "F1 Weighted: 0.4745 ± 0.0409\n",
      "Precision Macro: 0.4685 ± 0.0840\n",
      "Recall Macro: 0.4441 ± 0.0393\n",
      "F1 Macro: 0.4367 ± 0.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mash\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Mash\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Mash\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Mash\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PERFORMANCE COMPARISON SUMMARY\n",
      "==================================================\n",
      "Metric               Baseline RF     iRF             Improvement \n",
      "-----------------------------------------------------------------\n",
      "Accuracy             0.5020          0.5945          +18.42%\n",
      "F1 Weighted          0.4745          0.5736          +20.89%\n",
      "F1 Macro             0.4367          0.5281          +20.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mash\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Mash\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "# Configuration\n",
    "CSV_PATH = \"elections_with_perks_no_special.csv\"\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "N_SPLITS = 4\n",
    "\n",
    "# iRF Configuration\n",
    "IRF_ITERATIONS = 3  # Number of iRF iterations\n",
    "K_INTERACTIONS = 2  # Order of interactions to discover (2 = pairwise)\n",
    "TOP_K_FEATURES = 11  # Number of top features to consider for interactions\n",
    "\n",
    "# Fixed domains as provided\n",
    "CANDIDATES_DOMAIN = [\n",
    "    'Aatrox', 'Cole', 'Diana', 'Diaz', 'Finnegan', 'Foxy',\n",
    "    'Marina', 'Paul'\n",
    "]\n",
    "PERKS_DOMAIN = [\n",
    "    'Perks.ATimeForGiving', 'Perks.Benediction',\n",
    "    'Perks.BloomingBusiness','Perks.ChivalrousCarnival',\n",
    "    'Perks.DoubleTrouble', 'Perks.EZPZ', 'Perks.ExtraEvent',\n",
    "    'Perks.ExtraEventFishing_Festival', 'Perks.ExtraEventMining_Fiesta', 'Perks.ExtraEventSpooky_Festival',\n",
    "    'Perks.ExtraEventSweet_Tooth', 'Perks.FishingFestival', 'Perks.FishingXPBuff', 'Perks.GOATed',\n",
    "    'Perks.Marauder', 'Perks.MiningFiesta', 'Perks.MiningXPBuff',\n",
    "    'Perks.MoltenForge', 'Perks.MythologicalRitual', 'Perks.Pathfinder', 'Perks.PeltPocalypse',\n",
    "    'Perks.Perkpocalypse', 'Perks.PestEradicator', 'Perks.PetXPBuff', 'Perks.Prospection',\n",
    "    'Perks.SharingIsCaring', 'Perks.ShoppingSpree', 'Perks.SlashedPricing',\n",
    "    'Perks.SlayerXPBuff','Perks.StockExchange', 'Perks.SweetBenevolence',\n",
    "    'Perks.VolumeTrading'\n",
    "]\n",
    "\n",
    "\n",
    "def sparse_scale_features(X, feature_names, indicator_start_idx):\n",
    "    \"\"\"Apply sparse-aware scaling to features.\"\"\"\n",
    "    X_scaled = X.copy().astype(float)\n",
    "    \n",
    "    candidate_features = X_scaled[:, :len(CANDIDATES_DOMAIN)]\n",
    "    perk_features = X_scaled[:, len(CANDIDATES_DOMAIN):len(CANDIDATES_DOMAIN) + len(PERKS_DOMAIN)]\n",
    "    indicator_features = X_scaled[:, indicator_start_idx:]\n",
    "    \n",
    "    scaler_info = {}\n",
    "    \n",
    "    if indicator_features.shape[1] > 0:\n",
    "        non_zero_mask = indicator_features != 0\n",
    "        non_zero_values = indicator_features[non_zero_mask]\n",
    "        \n",
    "        if len(non_zero_values) > 0:\n",
    "            scaler = RobustScaler()\n",
    "            scaler.fit(indicator_features.reshape(-1, 1))\n",
    "            \n",
    "            indicator_scaled = indicator_features.copy()\n",
    "            indicator_scaled[non_zero_mask] = scaler.transform(\n",
    "                indicator_features[non_zero_mask].reshape(-1, 1)\n",
    "            ).flatten()\n",
    "            \n",
    "            X_scaled[:, indicator_start_idx:] = indicator_scaled\n",
    "            \n",
    "            scaler_info = {\n",
    "                'scaler': scaler,\n",
    "                'center': scaler.center_[0],\n",
    "                'scale': scaler.scale_[0],\n",
    "                'non_zero_count': len(non_zero_values),\n",
    "                'total_count': indicator_features.size,\n",
    "                'sparsity': 1 - (len(non_zero_values) / indicator_features.size)\n",
    "            }\n",
    "        else:\n",
    "            scaler_info = {'scaler': None, 'sparsity': 1.0}\n",
    "    \n",
    "    return X_scaled, scaler_info\n",
    "\n",
    "def load_data(csv_filename):\n",
    "    \"\"\"Load data and return features and target.\"\"\"\n",
    "    _df = pd.read_csv(csv_filename)\n",
    "\n",
    "    required_columns = {\"candidates\", \"perks\", \"mayor\"}\n",
    "    missing = required_columns - set(_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns in CSV: {missing}\")\n",
    "\n",
    "    if \"minister\" not in _df.columns:\n",
    "        raise ValueError(\"Expected 'minister' column not found in CSV.\")\n",
    "    minister_index = list(_df.columns).index(\"minister\")\n",
    "    _right_cols = list(_df.columns)[minister_index + 1 :]\n",
    "    _perk_indicator_cols = [c for c in _right_cols if c != \"mayor\"]\n",
    "\n",
    "\n",
    "    \n",
    "    rows = []\n",
    "    for _, row in _df.iterrows():\n",
    "        candidates = [c.strip() for c in str(row['candidates']).split(',') if c.strip()]\n",
    "        perks = [p.strip() for p in str(row['perks']).split(',') if p.strip()]\n",
    "        mayor = str(row['mayor']).strip()\n",
    "        \n",
    "        if mayor and mayor != 'nan':\n",
    "            perk_indicators = [float(row[col]) if not pd.isna(row[col]) else 0.0 \n",
    "                             for col in _perk_indicator_cols]\n",
    "            rows.append((candidates, perks, mayor, perk_indicators))\n",
    "\n",
    "    le_rf_cv = LabelEncoder()\n",
    "    le_rf_cv.fit(CANDIDATES_DOMAIN)\n",
    "    \n",
    "    valid_rows = []\n",
    "    for candidates, perks, mayor, perk_indicators in rows:\n",
    "        if mayor in CANDIDATES_DOMAIN:\n",
    "            valid_rows.append((candidates, perks, mayor, perk_indicators))\n",
    "    \n",
    "    rows = valid_rows\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for candidates, perks, mayor, perk_indicators in rows:\n",
    "        candidate_vec = [1 if c in candidates else 0 for c in CANDIDATES_DOMAIN]\n",
    "        perk_vec = [1 if p in perks else 0 for p in PERKS_DOMAIN]\n",
    "        perk_indicators_vec = perk_indicators\n",
    "        \n",
    "        X.append(candidate_vec + perk_vec + perk_indicators_vec)\n",
    "        y.append(mayor)\n",
    "    \n",
    "    feature_names = ([f\"cand_{c}\" for c in CANDIDATES_DOMAIN] + \n",
    "                    [f\"perk_{p}\" for p in PERKS_DOMAIN] + \n",
    "                    [f\"indicator_{col}\" for col in _perk_indicator_cols])\n",
    "    \n",
    "    indicator_start_idx = len(CANDIDATES_DOMAIN) + len(PERKS_DOMAIN)\n",
    "    \n",
    "    return np.array(X), np.array(y), feature_names, le_rf_cv, indicator_start_idx\n",
    "\n",
    "def create_interaction_features(X, feature_names, important_indices, k=2):\n",
    "    \"\"\"Create interaction features between important features.\"\"\"\n",
    "    X_interactions = []\n",
    "    interaction_names = []\n",
    "    \n",
    "    for combo in combinations(important_indices, k):\n",
    "        interaction_feature = np.prod(X[:, combo], axis=1)\n",
    "        X_interactions.append(interaction_feature)\n",
    "        \n",
    "        feature_combo_names = [feature_names[i] for i in combo]\n",
    "        interaction_name = \" * \".join(feature_combo_names)\n",
    "        interaction_names.append(f\"interaction_{interaction_name}\")\n",
    "    \n",
    "    if X_interactions:\n",
    "        X_interactions = np.column_stack(X_interactions)\n",
    "        return X_interactions, interaction_names\n",
    "    else:\n",
    "        return np.array([]).reshape(X.shape[0], 0), []\n",
    "\n",
    "def drop_zero_features(X):\n",
    "    \"\"\"Replace 0 values with np.nan to ignore them in predictions.\"\"\"\n",
    "    X = np.array(X, dtype=float)\n",
    "    X[X == 0] = np.nan\n",
    "    return X\n",
    "\n",
    "class IterativeRandomForest:\n",
    "    \"\"\"Iterative Random Forest implementation that discovers feature interactions.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=100, random_state=42, n_iterations=3, \n",
    "                 importance_threshold=0.01, k_interactions=2, top_k_features=20):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = random_state\n",
    "        self.n_iterations = n_iterations\n",
    "        self.importance_threshold = importance_threshold\n",
    "        self.k_interactions = k_interactions\n",
    "        self.top_k_features = top_k_features\n",
    "        \n",
    "        self.models_ = []\n",
    "        self.feature_names_history_ = []\n",
    "        self.importance_history_ = []\n",
    "        self.interaction_features_ = []\n",
    "        self.interaction_names_ = []\n",
    "        \n",
    "    def fit(self, X, y, feature_names):\n",
    "        \"\"\"Fit the iRF model with iterative feature selection and interaction discovery.\"\"\"\n",
    "        X_current = X.copy()\n",
    "        feature_names_current = feature_names.copy()\n",
    "        \n",
    "        for iteration in range(self.n_iterations):\n",
    "            rf = RandomForestClassifier(n_estimators=self.n_estimators, \n",
    "                                      random_state=self.random_state + iteration)\n",
    "            rf.fit(X_current, y)\n",
    "            \n",
    "            self.models_.append(rf)\n",
    "            self.feature_names_history_.append(feature_names_current.copy())\n",
    "            \n",
    "            importances = rf.feature_importances_\n",
    "            self.importance_history_.append(importances.copy())\n",
    "            \n",
    "            if iteration < self.n_iterations - 1:\n",
    "                top_indices = np.argsort(importances)[-self.top_k_features:]\n",
    "                \n",
    "                X_interactions, interaction_names = create_interaction_features(\n",
    "                    X_current, feature_names_current, top_indices, self.k_interactions\n",
    "                )\n",
    "                \n",
    "                if X_interactions.shape[1] > 0:\n",
    "                    X_current = np.column_stack([X_current, X_interactions])\n",
    "                    feature_names_current.extend(interaction_names)\n",
    "                    \n",
    "                    self.interaction_features_.extend(X_interactions.T)\n",
    "                    self.interaction_names_.extend(interaction_names)\n",
    "                \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using the final model.\"\"\"\n",
    "        if not self.models_:\n",
    "            raise ValueError(\"Model not fitted yet!\")\n",
    "        X = drop_zero_features(X)\n",
    "        return self.models_[-1].predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities using the final model.\"\"\"\n",
    "        if not self.models_:\n",
    "            raise ValueError(\"Model not fitted yet!\")\n",
    "        X = drop_zero_features(X)\n",
    "        return self.models_[-1].predict_proba(X)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"Get feature importance from the final model.\"\"\"\n",
    "        if not self.models_:\n",
    "            raise ValueError(\"Model not fitted yet!\")\n",
    "        return self.models_[-1].feature_importances_\n",
    "    \n",
    "    def get_final_feature_names(self):\n",
    "        \"\"\"Get feature names from the final iteration.\"\"\"\n",
    "        if not self.feature_names_history_:\n",
    "            raise ValueError(\"Model not fitted yet!\")\n",
    "        return self.feature_names_history_[-1]\n",
    "\n",
    "def print_performance_metrics(y_true, y_pred, class_names, title=\"Performance Metrics\"):\n",
    "    \"\"\"Print performance metrics\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{title}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    \n",
    "    print(f\"Overall: Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}\")\n",
    "    \n",
    "    precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, labels=range(len(class_names))\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nPer-Class:\")\n",
    "    print(f\"{'Class':<12} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name:<12} {precision_per_class[i]:<10.4f} {recall_per_class[i]:<10.4f} \"\n",
    "              f\"{f1_per_class[i]:<10.4f} {support_per_class[i]:<8}\")\n",
    "    \n",
    "    macro_precision = np.mean(precision_per_class)\n",
    "    macro_recall = np.mean(recall_per_class)\n",
    "    macro_f1 = np.mean(f1_per_class)\n",
    "    \n",
    "    print(f\"\\nMacro: Precision={macro_precision:.4f}, Recall={macro_recall:.4f}, F1={macro_f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_weighted': precision,\n",
    "        'recall_weighted': recall,\n",
    "        'f1_weighted': f1,\n",
    "        'precision_macro': macro_precision,\n",
    "        'recall_macro': macro_recall,\n",
    "        'f1_macro': macro_f1,\n",
    "        'precision_per_class': precision_per_class,\n",
    "        'recall_per_class': recall_per_class,\n",
    "        'f1_per_class': f1_per_class,\n",
    "        'support_per_class': support_per_class\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, title=\"Confusion Matrix\"):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load data and apply sparse scaling\n",
    "X_raw, y_irf, feature_names_irf, le_irf, indicator_start_idx = load_data(CSV_PATH)\n",
    "y_irf_enc = le_irf.transform(y_irf)\n",
    "class_names = le_irf.classes_\n",
    "\n",
    "# Apply sparse scaling\n",
    "X_irf, scaler_info = sparse_scale_features(X_raw, feature_names_irf, indicator_start_idx)\n",
    "\n",
    "# Store scaling information for later use\n",
    "normalization_results = {\n",
    "    'X_normalized': X_irf,\n",
    "    'y': y_irf_enc,\n",
    "    'feature_names': feature_names_irf,\n",
    "    'label_encoder': le_irf,\n",
    "    'scaler_info': scaler_info,\n",
    "    'indicator_start_idx': indicator_start_idx\n",
    "}\n",
    "\n",
    "# Create and fit iRF model\n",
    "irf_model = IterativeRandomForest(\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_iterations=IRF_ITERATIONS,\n",
    "    k_interactions=K_INTERACTIONS,\n",
    "    top_k_features=TOP_K_FEATURES\n",
    ")\n",
    "\n",
    "irf_model.fit(X_irf, y_irf_enc, feature_names_irf)\n",
    "\n",
    "# Get final feature importance\n",
    "final_importances = irf_model.get_feature_importance()\n",
    "final_feature_names = irf_model.get_final_feature_names()\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': final_feature_names,\n",
    "    'importance': final_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Analyze feature types\n",
    "candidate_features = feature_importance_df[feature_importance_df['feature'].str.startswith('cand_')]\n",
    "perk_features = feature_importance_df[feature_importance_df['feature'].str.startswith('perk_')]\n",
    "indicator_features = feature_importance_df[feature_importance_df['feature'].str.startswith('indicator_')]\n",
    "interaction_features = feature_importance_df[feature_importance_df['feature'].str.startswith('interaction_')]\n",
    "\n",
    "# Print top 15 most useful features\n",
    "print(\"=\"*80)\n",
    "print(\"TOP 15 MOST USEFUL FEATURES FOR THE MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Rank':<4} {'Feature':<40} {'Importance':<12} {'Type':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "top_15_features = feature_importance_df.head(15)\n",
    "for i, (_, row) in enumerate(top_15_features.iterrows(), 1):\n",
    "    feature_name = row['feature']\n",
    "    importance = row['importance']\n",
    "    \n",
    "    # Determine feature type\n",
    "    if feature_name.startswith('cand_'):\n",
    "        feature_type = \"Candidate\"\n",
    "    elif feature_name.startswith('perk_'):\n",
    "        feature_type = \"Perk\"\n",
    "    elif feature_name.startswith('indicator_'):\n",
    "        feature_type = \"Indicator\"\n",
    "    elif feature_name.startswith('interaction_'):\n",
    "        feature_type = \"Interaction\"\n",
    "    else:\n",
    "        feature_type = \"Other\"\n",
    "    \n",
    "    print(f\"{i:<4} {feature_name:<40} {importance:<12.6f} {feature_type:<15}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE TYPE BREAKDOWN IN TOP 15\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count feature types in top 15\n",
    "type_counts = {}\n",
    "for _, row in top_15_features.iterrows():\n",
    "    feature_name = row['feature']\n",
    "    if feature_name.startswith('cand_'):\n",
    "        feature_type = \"Candidate\"\n",
    "    elif feature_name.startswith('perk_'):\n",
    "        feature_type = \"Perk\"\n",
    "    elif feature_name.startswith('indicator_'):\n",
    "        feature_type = \"Indicator\"\n",
    "    elif feature_name.startswith('interaction_'):\n",
    "        feature_type = \"Interaction\"\n",
    "    else:\n",
    "        feature_type = \"Other\"\n",
    "    \n",
    "    type_counts[feature_type] = type_counts.get(feature_type, 0) + 1\n",
    "\n",
    "for feature_type, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    percentage = (count / 15) * 100\n",
    "    print(f\"{feature_type:<15}: {count:>2} features ({percentage:>5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# MODEL TESTING AND EVALUATION\n",
    "\n",
    "def create_test_features(X_test, irf_model):\n",
    "    \"\"\"Recreate the same feature engineering pipeline for test data.\"\"\"\n",
    "    X_test_augmented = X_test.copy()\n",
    "    \n",
    "    for iteration in range(len(irf_model.models_) - 1):\n",
    "        importances = irf_model.importance_history_[iteration]\n",
    "        top_indices = np.argsort(importances)[-TOP_K_FEATURES:]\n",
    "        \n",
    "        X_interactions_test = []\n",
    "        for combo in combinations(top_indices, K_INTERACTIONS):\n",
    "            if all(idx < X_test_augmented.shape[1] for idx in combo):\n",
    "                interaction_feature = np.prod(X_test_augmented[:, combo], axis=1)\n",
    "                X_interactions_test.append(interaction_feature)\n",
    "        \n",
    "        if X_interactions_test:\n",
    "            X_interactions_test = np.column_stack(X_interactions_test)\n",
    "            X_test_augmented = np.column_stack([X_test_augmented, X_interactions_test])\n",
    "    \n",
    "    return X_test_augmented\n",
    "\n",
    "def evaluate_irf_with_cv():\n",
    "    \"\"\"Evaluate iRF using cross-validation with proper feature reconstruction.\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    cv_scores = {\n",
    "        'accuracy': [],\n",
    "        'precision_weighted': [],\n",
    "        'recall_weighted': [],\n",
    "        'f1_weighted': [],\n",
    "        'precision_macro': [],\n",
    "        'recall_macro': [],\n",
    "        'f1_macro': []\n",
    "    }\n",
    "    \n",
    "    fold_predictions = []\n",
    "    fold_true_labels = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X_irf, y_irf_enc)):\n",
    "        X_train_fold, X_test_fold = X_irf[train_idx], X_irf[test_idx]\n",
    "        y_train_fold, y_test_fold = y_irf_enc[train_idx], y_irf_enc[test_idx]\n",
    "        \n",
    "        irf_fold = IterativeRandomForest(\n",
    "            n_estimators=N_ESTIMATORS,\n",
    "            random_state=RANDOM_STATE + fold,\n",
    "            n_iterations=IRF_ITERATIONS,\n",
    "            k_interactions=K_INTERACTIONS,\n",
    "            top_k_features=TOP_K_FEATURES\n",
    "        )\n",
    "        \n",
    "        irf_fold.fit(X_train_fold, y_train_fold, feature_names_irf)\n",
    "        \n",
    "        X_test_fold_augmented = create_test_features(X_test_fold, irf_fold)\n",
    "        \n",
    "        if X_test_fold_augmented.shape[1] != len(irf_fold.get_final_feature_names()):\n",
    "            n_features_needed = len(irf_fold.get_final_feature_names())\n",
    "            if X_test_fold_augmented.shape[1] > n_features_needed:\n",
    "                X_test_fold_augmented = X_test_fold_augmented[:, :n_features_needed]\n",
    "            elif X_test_fold_augmented.shape[1] < n_features_needed:\n",
    "                n_missing = n_features_needed - X_test_fold_augmented.shape[1]\n",
    "                padding = np.zeros((X_test_fold_augmented.shape[0], n_missing))\n",
    "                X_test_fold_augmented = np.column_stack([X_test_fold_augmented, padding])\n",
    "        \n",
    "        y_pred_fold = irf_fold.predict(X_test_fold_augmented)\n",
    "        \n",
    "        fold_predictions.extend(y_pred_fold)\n",
    "        fold_true_labels.extend(y_test_fold)\n",
    "        \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test_fold, y_pred_fold, average='weighted')\n",
    "        accuracy = np.mean(y_test_fold == y_pred_fold)\n",
    "        \n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "            y_test_fold, y_pred_fold, average='macro'\n",
    "        )\n",
    "        \n",
    "        cv_scores['accuracy'].append(accuracy)\n",
    "        cv_scores['precision_weighted'].append(precision)\n",
    "        cv_scores['recall_weighted'].append(recall)\n",
    "        cv_scores['f1_weighted'].append(f1)\n",
    "        cv_scores['precision_macro'].append(precision_macro)\n",
    "        cv_scores['recall_macro'].append(recall_macro)\n",
    "        cv_scores['f1_macro'].append(f1_macro)\n",
    "    \n",
    "    fold_predictions = np.array(fold_predictions)\n",
    "    fold_true_labels = np.array(fold_true_labels)\n",
    "    \n",
    "    return cv_scores\n",
    "\n",
    "def compare_with_baseline_rf():\n",
    "    \"\"\"Compare iRF performance with baseline Random Forest.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"COMPARISON: iRF vs BASELINE RANDOM FOREST\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    rf_baseline = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', \n",
    "               'precision_macro', 'recall_macro', 'f1_macro']\n",
    "    \n",
    "    baseline_cv_results = cross_validate(rf_baseline, X_irf, y_irf_enc, cv=skf, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    print(f\"\\nBaseline Random Forest ({N_SPLITS}-Fold CV):\")\n",
    "    for metric in scoring:\n",
    "        scores = baseline_cv_results[f'test_{metric}']\n",
    "        print(f\"{metric.replace('_', ' ').title()}: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "    \n",
    "    irf_cv_scores = evaluate_irf_with_cv()\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"PERFORMANCE COMPARISON SUMMARY\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    print(f\"{'Metric':<20} {'Baseline RF':<15} {'iRF':<15} {'Improvement':<12}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for metric in ['accuracy', 'f1_weighted', 'f1_macro']:\n",
    "        baseline_score = np.mean(baseline_cv_results[f'test_{metric}'])\n",
    "        irf_score = np.mean(irf_cv_scores[metric])\n",
    "        improvement = ((irf_score - baseline_score) / baseline_score) * 100\n",
    "        \n",
    "        print(f\"{metric.replace('_', ' ').title():<20} {baseline_score:<15.4f} {irf_score:<15.4f} {improvement:+.2f}%\")\n",
    "\n",
    "# Run the evaluation\n",
    "try:\n",
    "    compare_with_baseline_rf()\n",
    "except Exception as e:\n",
    "    X_train_simple, X_test_simple, y_train_simple, y_test_simple = train_test_split(\n",
    "        X_irf, y_irf_enc, test_size=0.3, random_state=RANDOM_STATE, stratify=y_irf_enc\n",
    "    )\n",
    "    \n",
    "    irf_simple = IterativeRandomForest(\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_iterations=IRF_ITERATIONS,\n",
    "        k_interactions=K_INTERACTIONS,\n",
    "        top_k_features=TOP_K_FEATURES\n",
    "    )\n",
    "    \n",
    "    irf_simple.fit(X_train_simple, y_train_simple, feature_names_irf)\n",
    "    \n",
    "    X_test_augmented = create_test_features(X_test_simple, irf_simple)\n",
    "    \n",
    "    if X_test_augmented.shape[1] != len(irf_simple.get_final_feature_names()):\n",
    "        n_features_needed = len(irf_simple.get_final_feature_names())\n",
    "        if X_test_augmented.shape[1] > n_features_needed:\n",
    "            X_test_augmented = X_test_augmented[:, :n_features_needed]\n",
    "        elif X_test_augmented.shape[1] < n_features_needed:\n",
    "            n_missing = n_features_needed - X_test_augmented.shape[1]\n",
    "            padding = np.zeros((X_test_augmented.shape[0], n_missing))\n",
    "            X_test_augmented = np.column_stack([X_test_augmented, padding])\n",
    "    \n",
    "    y_pred_simple = irf_simple.predict(X_test_augmented)\n",
    "    \n",
    "    print_performance_metrics(y_test_simple, y_pred_simple, class_names, \"iRF Simple Test\")\n",
    "    \n",
    "    rf_baseline_simple = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)\n",
    "    rf_baseline_simple.fit(X_train_simple, y_train_simple)\n",
    "    y_pred_baseline = rf_baseline_simple.predict(X_test_simple)\n",
    "    \n",
    "    print_performance_metrics(y_test_simple, y_pred_baseline, class_names, \"Baseline RF Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee0dae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the trained iRF model on the last row of the spreadsheet...\n",
      "================================================================================\n",
      "TESTING MODEL ON LAST ROW OF SPREADSHEET\n",
      "================================================================================\n",
      "Last row data:\n",
      "  Election number: 444\n",
      "  Date: September 22, 2025\n",
      "  Candidates: Aatrox,Cole,Diaz,Finnegan,Marina\n",
      "  Perks: Perks.SlashedPricing,Perks.Pathfinder,Perks.Prospection,Perks.MiningFiesta,Perks.LongTermInvestment,Perks.PestEradicator,Perks.GOATed,Perks.BloomingBusiness,Perks.FishingXPBuff,Perks.LuckOfTheSea\n",
      "  Mayor: nan (empty - perfect for testing!)\n",
      "  Minister: nan\n",
      "\n",
      "Processed data:\n",
      "  Candidates: ['Aatrox', 'Cole', 'Diaz', 'Finnegan', 'Marina']\n",
      "  Perks: ['Perks.SlashedPricing', 'Perks.Pathfinder', 'Perks.Prospection', 'Perks.MiningFiesta', 'Perks.LongTermInvestment', 'Perks.PestEradicator', 'Perks.GOATed', 'Perks.BloomingBusiness', 'Perks.FishingXPBuff', 'Perks.LuckOfTheSea']\n",
      "  Perk indicators: 37 values\n",
      "\n",
      "Feature vector created:\n",
      "  Shape: (1, 77)\n",
      "  Candidate features: 5/8 active\n",
      "  Perk features: 8/32 active\n",
      "  Perk indicator features: 37 values\n",
      "\n",
      "Active features:\n",
      "  Active candidates: ['Aatrox', 'Cole', 'Diaz', 'Finnegan', 'Marina']\n",
      "  Active perks: ['Perks.BloomingBusiness', 'Perks.FishingXPBuff', 'Perks.GOATed', 'Perks.MiningFiesta', 'Perks.Pathfinder', 'Perks.PestEradicator', 'Perks.Prospection', 'Perks.SlashedPricing']\n",
      "\n",
      "No scaling analysis results found. Using raw features.\n",
      "\n",
      "Creating interaction features for test data...\n",
      "  Original features: 77\n",
      "  Augmented features: 457\n",
      "  Interaction features added: 380\n",
      "\n",
      "Making prediction...\n",
      "\n",
      "==================================================\n",
      "PREDICTION RESULTS\n",
      "==================================================\n",
      "Predicted Mayor: Cole\n",
      "Confidence: 0.3900 (39.00%)\n",
      "\n",
      "All candidate probabilities:\n",
      "  Aatrox: 0.2433 (24.33%)\n",
      "  Cole: 0.3900 (39.00%)\n",
      "  Diana: 0.0733 (7.33%)\n",
      "  Diaz: 0.0433 (4.33%)\n",
      "  Finnegan: 0.0700 (7.00%)\n",
      "  Foxy: 0.0367 (3.67%)\n",
      "  Marina: 0.1100 (11.00%)\n",
      "  Paul: 0.0333 (3.33%)\n",
      "\n",
      "Top 3 predictions:\n",
      "  1. Cole: 0.3900 (39.00%)\n",
      "  2. Aatrox: 0.2433 (24.33%)\n",
      "  3. Marina: 0.1100 (11.00%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TEST MODEL ON LAST ROW OF SPREADSHEET\n",
    "# ============================================================================\n",
    "\n",
    "def test_model_on_last_row():\n",
    "    \"\"\"\n",
    "    Test the trained iRF model on the last row of the spreadsheet.\n",
    "    This row has no mayor value, making it perfect for prediction testing.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"TESTING MODEL ON LAST ROW OF SPREADSHEET\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load the CSV and get the last row\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    last_row = df.iloc[-1]\n",
    "    \n",
    "    print(f\"Last row data:\")\n",
    "    print(f\"  Election number: {last_row['election_number']}\")\n",
    "    print(f\"  Date: {last_row['date']}\")\n",
    "    print(f\"  Candidates: {last_row['candidates']}\")\n",
    "    print(f\"  Perks: {last_row['perks']}\")\n",
    "    print(f\"  Mayor: {last_row['mayor']} (empty - perfect for testing!)\")\n",
    "    print(f\"  Minister: {last_row['minister']}\")\n",
    "    \n",
    "    # Process the last row through the same feature engineering pipeline\n",
    "    candidates = [c.strip() for c in str(last_row['candidates']).split(',') if c.strip()]\n",
    "    perks = [p.strip() for p in str(last_row['perks']).split(',') if p.strip()]\n",
    "    \n",
    "    # Get perk indicator values (the columns after 'minister')\n",
    "    minister_index = list(df.columns).index(\"minister\")\n",
    "    perk_indicator_cols = [c for c in list(df.columns)[minister_index + 1:] if c != \"mayor\"]\n",
    "    perk_indicators = [float(last_row[col]) if not pd.isna(last_row[col]) else 0.0 \n",
    "                      for col in perk_indicator_cols]\n",
    "    \n",
    "    print(f\"\\nProcessed data:\")\n",
    "    print(f\"  Candidates: {candidates}\")\n",
    "    print(f\"  Perks: {perks}\")\n",
    "    print(f\"  Perk indicators: {len(perk_indicators)} values\")\n",
    "    \n",
    "    # Create feature vector (same as in load_data function)\n",
    "    # Binary vector for candidates (using fixed domain)\n",
    "    candidate_vec = [1 if c in candidates else 0 for c in CANDIDATES_DOMAIN]\n",
    "    # Binary vector for perks (using fixed domain)\n",
    "    perk_vec = [1 if p in perks else 0 for p in PERKS_DOMAIN]\n",
    "    # Perk indicator features\n",
    "    perk_indicators_vec = perk_indicators\n",
    "    \n",
    "    # Combine all features\n",
    "    X_test_row = np.array([candidate_vec + perk_vec + perk_indicators_vec])\n",
    "    \n",
    "    print(f\"\\nFeature vector created:\")\n",
    "    print(f\"  Shape: {X_test_row.shape}\")\n",
    "    print(f\"  Candidate features: {sum(candidate_vec)}/{len(candidate_vec)} active\")\n",
    "    print(f\"  Perk features: {sum(perk_vec)}/{len(perk_vec)} active\")\n",
    "    print(f\"  Perk indicator features: {len(perk_indicators_vec)} values\")\n",
    "    \n",
    "    # Show which candidates and perks are active\n",
    "    active_candidates = [CANDIDATES_DOMAIN[i] for i, val in enumerate(candidate_vec) if val == 1]\n",
    "    active_perks = [PERKS_DOMAIN[i] for i, val in enumerate(perk_vec) if val == 1]\n",
    "    \n",
    "    print(f\"\\nActive features:\")\n",
    "    print(f\"  Active candidates: {active_candidates}\")\n",
    "    print(f\"  Active perks: {active_perks}\")\n",
    "    \n",
    "    # Check if we have scaling results and apply the same scaling\n",
    "    try:\n",
    "        if 'scaling_analysis_results' in globals():\n",
    "            print(f\"\\nApplying scaling from scaling analysis...\")\n",
    "            best_strategy = scaling_analysis_results['best_strategy']\n",
    "            best_strategy_data = scaling_analysis_results['scaling_strategies'][best_strategy]\n",
    "            indicator_start_idx = scaling_analysis_results['indicator_start_idx']\n",
    "            \n",
    "            print(f\"  Using scaling strategy: {best_strategy}\")\n",
    "            print(f\"  Description: {best_strategy_data['description']}\")\n",
    "            \n",
    "            # Apply the same scaling to test data\n",
    "            X_test_scaled = X_test_row.copy()\n",
    "            if best_strategy_data['scaler'] is not None:\n",
    "                # Apply scaling to indicator features only\n",
    "                indicator_features = X_test_row[:, indicator_start_idx:]\n",
    "                X_test_scaled[:, indicator_start_idx:] = best_strategy_data['scaler'].transform(indicator_features)\n",
    "                print(f\"  Applied {type(best_strategy_data['scaler']).__name__} scaling to indicator features\")\n",
    "            else:\n",
    "                print(f\"  No scaler available for this strategy\")\n",
    "            \n",
    "            X_test_row = X_test_scaled\n",
    "        else:\n",
    "            print(f\"\\nNo scaling analysis results found. Using raw features.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError applying scaling: {e}\")\n",
    "        print(f\"Continuing with raw features...\")\n",
    "    \n",
    "    # Create test features with same interaction structure as training\n",
    "    print(f\"\\nCreating interaction features for test data...\")\n",
    "    X_test_augmented = create_test_features(X_test_row, irf_model)\n",
    "    \n",
    "    print(f\"  Original features: {X_test_row.shape[1]}\")\n",
    "    print(f\"  Augmented features: {X_test_augmented.shape[1]}\")\n",
    "    print(f\"  Interaction features added: {X_test_augmented.shape[1] - X_test_row.shape[1]}\")\n",
    "    \n",
    "    # Ensure test features match training features\n",
    "    if X_test_augmented.shape[1] != len(irf_model.get_final_feature_names()):\n",
    "        print(f\"  Adjusting feature dimensions...\")\n",
    "        n_features_needed = len(irf_model.get_final_feature_names())\n",
    "        if X_test_augmented.shape[1] > n_features_needed:\n",
    "            X_test_augmented = X_test_augmented[:, :n_features_needed]\n",
    "            print(f\"    Truncated to {n_features_needed} features\")\n",
    "        elif X_test_augmented.shape[1] < n_features_needed:\n",
    "            n_missing = n_features_needed - X_test_augmented.shape[1]\n",
    "            padding = np.zeros((X_test_augmented.shape[0], n_missing))\n",
    "            X_test_augmented = np.column_stack([X_test_augmented, padding])\n",
    "            print(f\"    Padded with {n_missing} zero features\")\n",
    "    \n",
    "    # Make prediction\n",
    "    print(f\"\\nMaking prediction...\")\n",
    "    try:\n",
    "        # Get prediction probabilities\n",
    "        prediction_proba = irf_model.predict_proba(X_test_augmented)\n",
    "        predicted_class_idx = np.argmax(prediction_proba[0])\n",
    "        predicted_mayor = le_irf.inverse_transform([predicted_class_idx])[0]\n",
    "        confidence = prediction_proba[0][predicted_class_idx]\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"PREDICTION RESULTS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Predicted Mayor: {predicted_mayor}\")\n",
    "        print(f\"Confidence: {confidence:.4f} ({confidence*100:.2f}%)\")\n",
    "        \n",
    "        # Show all candidate probabilities\n",
    "        print(f\"\\nAll candidate probabilities:\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            prob = prediction_proba[0][i]\n",
    "            print(f\"  {class_name}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "        \n",
    "        # Show top 3 predictions\n",
    "        top_3_indices = np.argsort(prediction_proba[0])[-3:][::-1]\n",
    "        print(f\"\\nTop 3 predictions:\")\n",
    "        for i, idx in enumerate(top_3_indices, 1):\n",
    "            class_name = class_names[idx]\n",
    "            prob = prediction_proba[0][idx]\n",
    "            print(f\"  {i}. {class_name}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "        \n",
    "        return {\n",
    "            'predicted_mayor': predicted_mayor,\n",
    "            'confidence': confidence,\n",
    "            'all_probabilities': dict(zip(class_names, prediction_proba[0])),\n",
    "            'top_3': [(class_names[idx], prediction_proba[0][idx]) for idx in top_3_indices]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error making prediction: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run the test\n",
    "print(\"Testing the trained iRF model on the last row of the spreadsheet...\")\n",
    "test_results = test_model_on_last_row()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
